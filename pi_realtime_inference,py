#!/usr/bin/env python3
# 按〔空白鍵〕開始錄 60 幀，完成後立即推論
import time, cv2, numpy as np, mediapipe as mp, tensorflow as tf
from keras.initializers import Orthogonal          # 自定 initializer
from picamera2 import Picamera2

MODEL_PATH = '/home/junwei/models/cnn_lstm_model.h5'
LABEL_PATH = '/home/junwei/models/label_encoder.npy'
SEQ_LEN    = 60            # 一次錄 60 幀

# ── 載入模型 ─────────────────────────────────────────────────────────
labels = np.load(LABEL_PATH)
model  = tf.keras.models.load_model(
    MODEL_PATH, custom_objects={'Orthogonal': Orthogonal}
)
print('✅  model OK, classes =', len(labels))

# ── 開啟相機 ─────────────────────────────────────────────────────────
cam = Picamera2()
cam.configure(cam.create_preview_configuration(
        main={'format': 'BGR888', 'size': (640,480)}))
cam.start(); time.sleep(1)

# ── Mediapipe Hands ────────────────────────────────────────────────
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1,
                       model_complexity=0,
                       min_detection_confidence=0.5,
                       min_tracking_confidence=0.5)
draw  = mp.solutions.drawing_utils
DIM   = 63                    # 21 點 × (x,y,z)

# ── 主迴圈 ───────────────────────────────────────────────────────────
capturing = False             # 是否正在錄製
seq       = []                # 暫存 60 幀特徵
prediction= 'press <space>'   # 畫面右上角顯示的文字
t_prev    = time.time()

try:
    while True:
        frm = cam.capture_array()
        frm = cv2.flip(frm, 1)                      # 左右鏡像

        # ------------- 偵測手部關鍵點 -------------
        res = hands.process(cv2.cvtColor(frm, cv2.COLOR_BGR2RGB))

        hand_lm = None                                 # ← 預設沒有手
        if res.multi_hand_landmarks:                   # 偵測到至少一隻手
            hand_lm = res.multi_hand_landmarks[0]      # 取第一隻
            draw.draw_landmarks(frm, hand_lm, mp_hands.HAND_CONNECTIONS)

        # ------------- 是否在錄製？ -------------
        if capturing:
            if hand_lm:                            # 有手 → 存關鍵點
                feat = [c for p in hand_lm.landmark for c in (p.x,p.y,p.z)]
            else:                                  # 沒偵測到手 → 全 0
                feat = [0.0]*DIM
            seq.append(feat)

            # 畫進度條／文字
            cv2.rectangle(frm, (10,100),
                          (10+int(400*len(seq)/SEQ_LEN), 120), (0,255,0), -1)
            cv2.rectangle(frm, (10,100), (410,120), (255,255,255), 2)
            cv2.putText(frm, f'{len(seq):>2}/{SEQ_LEN}',
                        (420,118), cv2.FONT_HERSHEY_SIMPLEX, 0.6,
                        (0,255,0), 2, cv2.LINE_AA)

            # 集滿 60 幀 → 推論
            if len(seq) == SEQ_LEN:
                x = np.asarray(seq, np.float32)[None, ...]      # (1,60,63)
                y = model(x, training=False).numpy()[0]
                prediction = labels[int(y.argmax())]
                seq.clear()
                capturing = False

        # ------------- FPS 與結果 -------------
        fps = 1. / (time.time() - t_prev); t_prev = time.time()
        cv2.putText(frm, f'FPS:{fps:4.1f}', (10,30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2, cv2.LINE_AA)
        cv2.putText(frm, f'{prediction}', (10,70),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,0), 3, cv2.LINE_AA)

        cv2.imshow('Sign-Language Realtime', frm)

        # ------------- 鍵盤事件 -------------
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):                        # q → 離開
            break
        if key == ord(' '):                       # space → 重新開始錄製
            capturing  = True
            seq.clear()
            prediction = 'Recording...'

finally:
    hands.close()
    cam.stop()
    cv2.destroyAllWindows()
